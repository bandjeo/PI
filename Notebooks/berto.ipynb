{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "progressive-color",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "differential-walker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import codecs\n",
    "import re\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-europe",
   "metadata": {},
   "source": [
    "## Loading the model\n",
    "Load the paraphrase-xlm-r-multilingual-v1 model, and use gpu if it is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aware-interest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dusanpanda/.pyenv/versions/3.8.7/envs/PI/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('paraphrase-xlm-r-multilingual-v1')\n",
    "if torch.cuda.is_available():\n",
    "   model = model.to(torch.device(\"cuda\"))\n",
    "print(model.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-drunk",
   "metadata": {},
   "source": [
    "## Example\n",
    "Test multi lingual sentence embeddings by doing cosine similarity between similar sentences in different languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "quarterly-orientation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t Мачка седи напољу \t\t Score: 0.9889\n",
      "A man is playing guitar \t\t Човек свира гитару \t\t Score: 0.9719\n",
      "The new movie is awesome \t\t Нови филм је сјајан \t\t Score: 0.8863\n"
     ]
    }
   ],
   "source": [
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['Мачка седи напољу',\n",
    "              'Човек свира гитару',\n",
    "              'Нови филм је сјајан']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heated-longitude",
   "metadata": {},
   "source": [
    "## Embed the documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norman-forward",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ongoing-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../acts'\n",
    "dataset = {}\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "for file_path in os.listdir(dataset_path):\n",
    "    with codecs.open(os.path.join(dataset_path, file_path), 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        data = data.lower() #lowercase\n",
    "        data = TAG_RE.sub('', data) #remove html tags\n",
    "        data = \" \".join(data.split()) #remove extra whitespaces\n",
    "        dataset[file_path] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sustained-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(dataset.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-damage",
   "metadata": {},
   "source": [
    "### Embed the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "through-pickup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6946731ad6d24c4695ce0b8711ee15ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = model.encode(corpus, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "noble-memory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "<class 'torch.Tensor'>\n",
      "tensor([ 2.6268e-01,  2.1535e-01,  4.7530e-02,  3.2643e-01, -6.4580e-01,\n",
      "         1.4841e-02,  6.6523e-02,  1.5537e-01,  1.1395e-01,  8.5271e-02,\n",
      "         1.9012e-01,  8.8985e-03, -2.8907e-02,  8.4982e-03,  3.8316e-02,\n",
      "        -2.5428e-01,  3.0941e-01, -2.1273e-02,  3.3076e-03, -1.1747e-01,\n",
      "        -9.0544e-02, -3.3897e-01, -1.6136e-01,  9.3052e-02,  2.3413e-01,\n",
      "         1.6467e-01,  2.9227e-01,  1.8580e-01, -3.2769e-01, -3.5479e-02,\n",
      "         2.3625e-02, -1.3125e-01, -3.1069e-02,  4.2423e-02, -1.0064e-01,\n",
      "         2.1015e-01,  8.4453e-02,  1.6454e-01, -1.2877e-01,  2.5345e-02,\n",
      "         4.2720e-01,  5.6138e-02, -9.3906e-02,  3.4160e-01, -2.5491e-02,\n",
      "        -7.9388e-02, -2.2092e-01, -2.3218e-01, -2.1752e-03, -1.7837e-02,\n",
      "        -4.9334e-02,  1.9557e-01,  6.1125e-03,  4.2973e-02, -1.9483e-01,\n",
      "         1.5243e-01,  9.1909e-02,  1.4664e-01,  1.9402e-01,  2.5061e-01,\n",
      "        -1.6577e-01,  6.6146e-02, -5.8396e-02,  3.4775e-01,  2.5780e-01,\n",
      "         4.6226e-02,  2.4055e-01, -1.9710e-01, -2.4478e-01, -9.7130e-02,\n",
      "        -1.7983e-01,  2.0145e-02,  2.2903e-01, -7.6082e-02,  1.8936e-01,\n",
      "         4.8694e-01,  8.6245e-04, -1.2773e-01, -1.6051e-01,  1.5355e-02,\n",
      "        -8.3986e-02, -1.2626e-01,  1.8719e-01,  4.2234e-02, -7.5397e-02,\n",
      "        -1.9229e-01, -2.3347e-01, -4.1523e-01, -3.1699e-01,  9.0196e-02,\n",
      "        -8.5248e-02, -2.1235e-01, -5.8456e-03, -8.6090e-02, -8.6080e-02,\n",
      "         3.6172e-01, -1.5971e-01, -2.0374e-01,  6.7946e-02, -2.6428e-01,\n",
      "         2.7272e-02, -1.3618e-01,  1.8110e-01,  1.8280e-01,  2.6535e-02,\n",
      "         9.7570e-02, -3.8484e-01,  2.7591e-01,  7.6834e-03,  2.5256e-01,\n",
      "         2.8560e-02,  1.9335e-01, -9.7124e-02, -8.6631e-02,  1.2234e-01,\n",
      "         1.2594e-01,  2.0947e-02, -1.0670e-01,  2.3196e-02, -1.0428e-01,\n",
      "         5.0266e-02,  2.7880e-01, -1.6056e-01,  1.9273e-01,  1.3930e-01,\n",
      "         1.3697e-01, -2.5958e-01,  3.4851e-02,  4.2700e-02,  1.9909e-01,\n",
      "         7.4431e-02, -3.5987e-02,  2.9019e-01, -2.7737e-01,  3.2715e-01,\n",
      "        -3.8319e-02,  5.5512e-02, -3.2732e-04,  2.9984e-01,  3.0478e-01,\n",
      "        -7.3425e-02, -2.2049e-01, -1.0165e-01, -1.1119e-01,  1.1578e-01,\n",
      "         1.1328e-01,  4.1366e-01, -7.0357e-02,  4.7728e-01, -1.9935e-01,\n",
      "        -3.4412e-02,  2.1462e-01,  8.4963e-03, -3.7233e-01, -2.2471e-01,\n",
      "         3.9701e-01,  3.1558e-01, -3.4900e-01,  5.1380e-02, -2.4701e-02,\n",
      "         1.3332e-01, -2.5040e-01, -1.6874e-01, -6.4871e-02, -9.4999e-02,\n",
      "        -1.1034e-01, -1.7751e-01, -1.8430e-01, -2.6388e-01,  1.1513e-01,\n",
      "        -2.6872e-01, -1.3287e-01, -2.2401e-01,  4.0598e-02, -2.6430e-01,\n",
      "        -1.3883e-01, -2.4282e-01,  1.2787e-01, -1.2218e-01,  9.7549e-02,\n",
      "         1.9831e-01, -4.2708e-02,  3.6333e-02,  1.0555e-01,  1.2472e-01,\n",
      "        -5.3547e-02,  9.7235e-02,  2.3045e-01,  2.7401e-01,  4.2691e-02,\n",
      "        -1.5676e-01,  1.3210e-01, -3.5401e-01,  1.1537e-01,  6.8214e-02,\n",
      "         6.9646e-02,  2.0089e-01,  8.2594e-02,  5.6437e-01, -3.4560e-03,\n",
      "        -2.4346e-01,  1.5052e-01, -3.3664e-01,  2.5941e-01,  3.9757e-02,\n",
      "         1.5971e-01, -4.8198e-01,  2.5465e-01,  2.0997e-01,  1.6105e-01,\n",
      "        -6.6147e-03,  1.0439e-01,  2.1813e-01,  1.2440e-01, -3.7245e-01,\n",
      "         8.2268e-02,  2.8706e-01,  1.9595e-01,  6.9385e-02,  6.8519e-03,\n",
      "         9.2875e-03,  1.2838e-01,  2.2497e-01, -2.7969e-01, -5.2085e-02,\n",
      "         8.0873e-02,  4.5299e-02, -8.3884e-02,  2.2175e-01, -3.5504e-01,\n",
      "         1.3982e-01,  5.3810e-02, -6.9658e-02, -2.3985e-01, -5.8523e-04,\n",
      "         4.9929e-01, -1.3171e-01,  1.1753e-01,  1.0892e-01, -7.7909e-02,\n",
      "         4.0888e-01,  5.7336e-02,  9.4707e-03,  3.8384e-02, -3.2876e-02,\n",
      "        -2.3115e-01, -3.6079e-02,  8.6995e-02, -1.8045e-01, -3.6600e-01,\n",
      "         4.3904e-01, -4.7013e-01, -9.3898e-02,  2.0530e-02,  3.3170e-01,\n",
      "        -1.7866e-01,  1.0687e-02, -1.2978e-01, -3.7830e-02,  4.2618e-01,\n",
      "         2.7873e-02, -3.9086e-02, -9.9997e-02,  1.8116e-01,  8.9851e-02,\n",
      "         1.7325e-01, -9.6183e-02,  2.6740e-01,  3.9412e-01, -1.0624e-01,\n",
      "         1.9084e-01,  1.2139e-01,  1.1470e-01, -1.7766e-01, -1.2890e-01,\n",
      "         2.4939e-04, -9.2549e-02,  1.8156e-01,  4.0917e-02,  1.6826e-01,\n",
      "        -1.7874e-01, -2.3432e-01, -1.3435e-01, -3.0557e-01, -1.1290e-01,\n",
      "        -8.2684e-02, -1.8560e-01, -7.8247e-02,  2.7265e-01, -1.9771e-01,\n",
      "         5.2242e-02, -2.1584e-02, -2.0913e-01,  1.0165e-01, -7.7087e-02,\n",
      "        -1.8318e-01,  1.2606e-01, -4.0084e-01,  9.3324e-02, -2.1829e-02,\n",
      "        -3.1737e-01,  3.0002e-01, -1.5659e-01,  9.8613e-02,  1.1946e-01,\n",
      "        -2.3647e-01, -2.8677e-02, -1.5405e-01, -1.2476e-01,  3.0923e-01,\n",
      "        -2.8806e-01,  2.6345e-01,  1.8224e-01,  1.6071e-01,  3.5430e-01,\n",
      "         3.2076e-01, -2.4168e-02,  3.3647e-02, -2.0079e-01, -1.7156e-01,\n",
      "        -1.5248e-01,  1.1730e-01,  4.5050e-02, -7.8823e-02,  1.6964e-02,\n",
      "         6.4453e-01, -6.2436e-02, -4.2746e-01,  1.9826e-01, -1.3324e-02,\n",
      "         1.3232e-01, -1.1829e-01,  1.3926e-01, -1.3283e-01, -1.1030e-01,\n",
      "         1.4696e-01, -3.3330e-01,  1.1268e-01,  4.9724e-02,  1.3740e-01,\n",
      "         1.3692e-01,  4.5115e-02,  1.8917e-03, -1.2154e-01,  2.7920e-01,\n",
      "         1.2113e-01,  8.7946e-03, -5.0763e-02, -1.0675e-01, -1.9944e-01,\n",
      "        -1.9373e-01, -1.0669e-01,  5.7545e-02, -1.5953e-01,  1.6163e-01,\n",
      "         1.0273e-01,  1.0906e-01,  1.2488e-01,  1.8770e-01,  1.7618e-01,\n",
      "        -7.1015e-02, -1.0079e-02,  7.5512e-03, -3.6373e-02,  4.7758e-02,\n",
      "        -3.0887e-01,  2.5137e-01,  2.0482e-01, -1.4976e-01,  4.7303e-01,\n",
      "         6.4437e-02,  2.1028e-01, -1.6394e-01,  6.5585e-02,  6.0695e-02,\n",
      "         7.8529e-02,  1.9387e-01,  2.0393e-01,  5.5956e-02,  1.4570e-01,\n",
      "         1.9568e-01,  2.2549e-02, -3.6086e-01,  4.8346e-02, -2.7165e-01,\n",
      "        -6.9870e-02, -1.2090e-01,  1.3013e-01,  2.9269e-01, -1.1789e-01,\n",
      "         1.2094e-01, -1.4584e-01, -3.9773e-01, -3.0182e-01,  1.2893e-01,\n",
      "         1.5790e-01,  1.3122e-01,  6.1390e-02,  8.3545e-02,  2.4307e-01,\n",
      "        -1.1373e-01,  5.0701e-02, -2.5228e-02,  5.7530e-01, -5.8065e-04,\n",
      "        -6.2693e-01,  3.1631e-01,  9.5750e-02,  3.3248e-01,  3.8207e-01,\n",
      "         1.5539e-01,  1.1596e-01,  1.1540e-02, -4.8237e-01, -2.2945e-02,\n",
      "         2.2171e-01,  6.0157e-01,  1.4790e-01, -1.2073e-01,  2.3770e-01,\n",
      "        -4.9498e-01,  5.8106e-02,  4.4063e-01, -1.6465e-01,  3.4434e-01,\n",
      "        -7.3925e-03,  2.0075e-01, -4.1590e-02, -1.0811e-01, -3.3093e-01,\n",
      "         1.3787e-01, -1.1589e-01,  4.2492e-02,  1.4106e-01,  5.9556e-02,\n",
      "         1.6316e-01,  4.4358e-01,  2.9647e-01, -4.3394e-02, -1.5538e-01,\n",
      "        -3.2512e-01, -1.9874e-02, -4.6012e-02, -2.6235e-01,  7.8661e-02,\n",
      "         3.4978e-02, -7.1457e-02, -1.8549e-01,  7.6703e-02, -1.6669e-01,\n",
      "        -1.3989e-01, -3.5765e-02, -5.1717e-01,  4.7179e-02,  7.2101e-02,\n",
      "        -2.4345e-02, -1.0455e-01,  6.9973e-02, -2.4460e-01,  4.5017e-02,\n",
      "         2.5265e-02, -5.3232e-02, -1.6189e-01, -3.4664e-02,  3.4166e-01,\n",
      "         1.5754e-01,  2.0182e-01,  2.6504e-01,  1.8798e-02,  1.5918e-01,\n",
      "        -1.4496e-01, -1.4558e-01, -1.2496e-01, -9.0243e-03,  1.4897e-01,\n",
      "         8.0528e-02, -1.1729e-01, -2.5175e-01, -9.6121e-02,  1.3539e-02,\n",
      "         2.9513e-01, -7.5121e-02, -1.9910e-02, -5.3877e-03, -5.6499e-02,\n",
      "        -1.0465e-01, -1.3831e-01, -1.4324e-01, -9.1970e-02,  7.9489e-02,\n",
      "        -1.2615e-01,  1.6422e-01, -2.3008e-01,  1.5723e-01,  2.2981e-02,\n",
      "         1.5956e-02, -8.0203e-02,  3.0521e-01, -5.1093e-02,  3.6213e-01,\n",
      "        -1.1015e-02, -6.0394e-02,  1.7297e-01,  1.6697e-01, -2.6359e-02,\n",
      "         2.1100e-01,  1.8583e-01, -9.1365e-02,  2.3507e-01, -5.0512e-02,\n",
      "         4.7860e-01,  1.9842e-01,  2.3038e-02, -2.9544e-01,  1.2958e-01,\n",
      "         1.4822e-01,  1.2193e-01, -8.3667e-02,  4.3903e-01,  2.0029e-01,\n",
      "        -6.4155e-02, -3.2232e-03,  3.2815e-02, -9.7138e-03, -1.6909e-01,\n",
      "         1.0249e-01, -1.2838e-01, -6.7726e-02,  1.1439e-01,  2.0493e-01,\n",
      "         1.8327e-01,  1.4682e-02,  1.9032e-02, -1.2254e-01, -2.3409e-02,\n",
      "         5.6581e-03,  1.0993e-01,  1.6204e-01, -5.6396e-01, -1.5032e-01,\n",
      "         3.8324e-01,  2.0482e-01,  2.4098e-01, -1.7717e-01,  8.3440e-02,\n",
      "         6.8700e-03,  4.9372e-01, -3.2890e-01, -1.3627e-01, -4.1150e-01,\n",
      "        -3.8169e-02,  1.0070e-01, -1.7137e-01,  1.6188e-01, -1.1569e-01,\n",
      "        -5.4285e-02,  3.0936e-01, -1.2970e-01, -8.8658e-02,  4.1458e-01,\n",
      "        -2.1785e-01,  2.8136e-01,  5.8618e-02,  5.3512e-02, -4.2427e-02,\n",
      "        -1.6323e-02,  4.0230e-02, -4.3912e-01,  1.6995e-01,  5.6930e-02,\n",
      "         3.7791e-01,  1.2495e-01,  8.5522e-02, -5.6292e-02,  3.6305e-01,\n",
      "        -1.1604e-01,  1.8142e-01, -2.8268e-01, -2.2675e-01,  1.3670e-02,\n",
      "         1.4284e-01, -1.7421e-01,  2.0253e-01, -1.3674e-01,  1.9769e-01,\n",
      "         1.3656e-01, -2.1556e-01, -1.2414e-01,  7.7950e-03,  1.9562e-01,\n",
      "         7.3314e-02,  6.7604e-02,  3.7098e-01,  1.2819e-01,  4.3782e-02,\n",
      "        -2.9766e-02, -1.0675e-01,  1.0164e-01, -2.7463e-03, -1.6017e-02,\n",
      "        -3.2662e-01, -1.1017e-01, -1.5640e-01,  2.8385e-01,  1.0071e-01,\n",
      "         1.7420e-01,  3.8057e-01,  1.2296e-01, -9.8613e-02, -1.7313e-01,\n",
      "         1.2624e-01, -1.9906e-01, -3.1446e-01,  4.0703e-01, -2.0657e-02,\n",
      "        -1.1013e-01, -6.7762e-02, -1.8619e-02,  1.0493e-02,  1.5592e-01,\n",
      "        -3.5844e-01, -1.4221e-01, -2.3539e-02,  1.3967e-01,  3.7791e-01,\n",
      "        -3.1510e-01,  3.7041e-03, -6.2446e-02,  2.0563e-01,  1.1976e-01,\n",
      "         1.1544e-01,  5.8220e-01,  7.8818e-02,  3.6859e-02, -3.6301e-01,\n",
      "         1.9913e-02,  2.2786e-01, -1.5497e-02,  4.2359e-01, -1.7717e-01,\n",
      "         9.0208e-02,  9.9879e-02,  6.6941e-03, -3.6374e-01, -7.7645e-02,\n",
      "         1.3479e-01,  1.3531e-01, -3.4786e-02,  1.0040e-01, -1.5290e-01,\n",
      "        -1.3484e-01, -2.1021e-01, -3.1769e-01, -2.9218e-01, -1.5930e-01,\n",
      "         2.8389e-01, -4.7556e-01,  9.4492e-03, -2.6455e-01,  1.7314e-01,\n",
      "         7.3321e-02,  2.5755e-01, -1.7815e-01,  4.5999e-01,  1.1208e-01,\n",
      "         1.3008e-01, -1.1340e-01, -2.2689e-01,  1.5424e-01, -1.2990e-01,\n",
      "         1.7124e-01, -3.2660e-01,  4.2894e-01,  1.0183e-01, -3.8746e-01,\n",
      "         3.4908e-01, -1.5504e-01,  6.1763e-02,  1.8573e-01,  6.5530e-02,\n",
      "         1.6767e-01, -4.3559e-02,  1.5997e-01,  8.4935e-02, -1.5572e-01,\n",
      "        -2.4952e-01,  8.8281e-02,  8.6366e-02,  1.0655e-01, -3.3024e-02,\n",
      "         6.4266e-02,  2.4974e-01, -3.1068e-01, -5.2807e-01, -4.8141e-01,\n",
      "         3.4688e-01, -7.3921e-02, -1.0090e-01, -1.9723e-01,  2.6862e-01,\n",
      "         5.0220e-02,  3.0447e-01,  3.3958e-01, -1.4253e-02, -4.1487e-02,\n",
      "        -1.3361e-01,  4.6903e-02, -2.1715e-02,  1.1496e-01,  6.2235e-02,\n",
      "         1.2167e-01,  1.6605e-01, -9.1340e-02,  1.5863e-01,  1.3149e-01,\n",
      "        -2.1830e-01,  1.0052e-01,  2.3922e-01, -1.1909e-01,  1.0809e-02,\n",
      "        -2.9460e-01, -2.0803e-01, -3.1670e-02,  2.5882e-01, -2.0520e-01,\n",
      "        -1.6916e-01,  1.4450e-01, -2.6573e-01,  2.9798e-01, -1.5763e-02,\n",
      "        -9.2106e-03,  2.0554e-01,  1.8491e-02, -3.2950e-02,  1.3057e-01,\n",
      "        -5.6187e-02, -2.4093e-01, -1.5153e-01, -1.3492e-02,  9.5903e-02,\n",
      "        -2.6225e-01,  6.3292e-02, -5.7063e-02, -2.5922e-01, -1.7668e-01,\n",
      "         4.5448e-02, -4.6515e-02,  1.3332e-01,  6.8529e-02, -1.1885e-01,\n",
      "         5.5013e-01, -1.3546e-01,  1.6199e-02, -1.5070e-02,  3.4599e-01,\n",
      "         3.5877e-01,  2.0935e-02, -1.5622e-01, -1.5580e-01, -3.5531e-01,\n",
      "         1.0753e-01, -3.4680e-01, -2.0838e-01,  1.8528e-01,  4.2611e-01,\n",
      "         4.8413e-01,  3.9215e-02, -2.1859e-02])\n"
     ]
    }
   ],
   "source": [
    "print(type(embeddings))\n",
    "print(type(embeddings[0]))\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "mental-steal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00607183],\n",
       "       [ 0.03425825],\n",
       "       [ 0.07264607],\n",
       "       ...,\n",
       "       [ 0.1150783 ],\n",
       "       [-0.0054166 ],\n",
       "       [ 0.04229683]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_scores = util.pytorch_cos_sim(embeddings, embeddings2[0])\n",
    "cosine_scores.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cooperative-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(X, model, query, top_k=10):\n",
    "    \"\"\" Vectorizes the `query` via `vectorizor` and calculates the cosine similarity of\n",
    "    the `query` and `X` (all the documents) and returns the `top_k` similar documents.\"\"\"\n",
    "\n",
    "    # Vectorize the query to the same length as documents\n",
    "    query_vec = model.encode(query, convert_to_tensor=True)\n",
    "    # Compute the cosine similarity between query_vec and all the documents\n",
    "    cosine_similarities = util.pytorch_cos_sim(X, query_vec).numpy().flatten()\n",
    "    # Sort the similar documents from the most similar to less similar and return the indices\n",
    "    most_similar_doc_indices = np.argsort(cosine_similarities, axis=0)[:-top_k-1:-1]\n",
    "    return (most_similar_doc_indices, cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "lovely-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similar_documents(df, cosine_similarities, similar_doc_indices):\n",
    "    \"\"\" Prints the most similar documents using indices in the `similar_doc_indices` vector.\"\"\"\n",
    "    counter = 1\n",
    "    for index in similar_doc_indices:\n",
    "        print('Top-{}, Similarity = {}'.format(counter, cosine_similarities[index]))\n",
    "        print('body: {}, '.format(df[index]))\n",
    "        print()\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bacterial-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search time: 63.87 ms\n",
      "\n",
      "Top-1, Similarity = 0.6095771789550781\n",
      "body: 190.html, \n",
      "\n",
      "Top-2, Similarity = 0.5718044638633728\n",
      "body: 450.html, \n",
      "\n",
      "Top-3, Similarity = 0.5671951770782471\n",
      "body: 194.html, \n",
      "\n",
      "Top-4, Similarity = 0.5632493495941162\n",
      "body: 698.html, \n",
      "\n",
      "Top-5, Similarity = 0.548108696937561\n",
      "body: 448.html, \n",
      "\n",
      "Top-6, Similarity = 0.545495867729187\n",
      "body: 502.html, \n",
      "\n",
      "Top-7, Similarity = 0.5452719926834106\n",
      "body: 201.html, \n",
      "\n",
      "Top-8, Similarity = 0.5430032014846802\n",
      "body: 199.html, \n",
      "\n",
      "Top-9, Similarity = 0.5397124886512756\n",
      "body: 200.html, \n",
      "\n",
      "Top-10, Similarity = 0.5395081043243408\n",
      "body: 282.html, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_question = [u'порез казна камата']\n",
    "search_start = time.time()\n",
    "sim_vecs, cosine_similarities = calculate_similarity(embeddings, model, user_question)\n",
    "search_time = time.time() - search_start\n",
    "print(\"search time: {:.2f} ms\".format(search_time * 1000))\n",
    "print()\n",
    "show_similar_documents(list(dataset.keys()), cosine_similarities, sim_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-talent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
